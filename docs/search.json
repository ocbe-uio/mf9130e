[
  {
    "objectID": "course_material/course_material_overview.html",
    "href": "course_material/course_material_overview.html",
    "title": "Course material",
    "section": "",
    "text": "On this page you’ll find a list of material used in this course.\nFor the exercises and lab notes we use during the lab sessions, please check the R Lab and Code."
  },
  {
    "objectID": "course_material/course_material_overview.html#week-1",
    "href": "course_material/course_material_overview.html#week-1",
    "title": "Course material",
    "section": "Week 1",
    "text": "Week 1\n\n\n\nTime\nTopic\nLecture notes\nLab\nOther\n\n\n\n\nApril 24 PM\nCourse introduction\nSlides\n\n\n\n\n\nDescriptive statistics\nSlides, K&S chapter 2-4, Aalen chapter 1-2\n\nPaper 1, Paper 2, Paper 3\n\n\nApril 25 AM\nIntroduction to R and Rstudio\nSlides\nIntro to RStudio, Intro to R\n\n\n\n\nLab session\nSlides\nDescriptive statistics (EDA I)\n\n\n\nApril 25 PM\nProbability, diagnosistic tests\nIntro slides Probability Diagnostic tests\n\n\n\n\n\nStatistical distributions\nDistributions\n\n\n\n\nApril 26 AM\nLab session\n\nCOVID-19 tests, Simulations\n\n\n\nApril 26 PM\nStatistical inference, tests and confidence intervals\n\n\n\n\n\n\nt-tests\n\n\n\n\n\nApril 27 AM\nLab session\n\n\n\n\n\nApril 27 PM\nCategorical data, table analysis\n\n\n\n\n\nApril 28 AM\nLab session"
  },
  {
    "objectID": "course_material/course_material_overview.html#week-2",
    "href": "course_material/course_material_overview.html#week-2",
    "title": "Course material",
    "section": "Week 2",
    "text": "Week 2\n\n\n\n\n\n\n\n\n\n\nTime\nTopic\nLecture notes\nLab\nOther\n\n\n\n\nMay 8 AM\nExploratory data analysis, transformation\n\n\n\n\n\n\nNon-parametric methods\n\n\n\n\n\nMay 8 PM\nSample size, statistical power\n\n\n\n\n\nMay 9 AM\nStudy design, principles of clinical trials\n\n\n\n\n\nMay 9 PM\nLinear regression I\n\n\n\n\n\nMay 10 AM\nLinear regression II\n\n\n\n\n\nMay 10 PM\nSurvival analysis"
  },
  {
    "objectID": "lab/lab_eda_part1.html",
    "href": "lab/lab_eda_part1.html",
    "title": "Exploratory data analysis (Part I)",
    "section": "",
    "text": "Datasets\nR script (link)"
  },
  {
    "objectID": "lab/lab_eda_part1.html#exercise-1-weight",
    "href": "lab/lab_eda_part1.html#exercise-1-weight",
    "title": "Exploratory data analysis (Part I)",
    "section": "Exercise 1 (weight)",
    "text": "Exercise 1 (weight)\n\n1a\nGenerate a variable named weight, with the following measurements:\n50 75 70 74 95 83 65 94 66 65 65 75 84 55 73 68 72 67 53 65\n\nweight <- c(50, 75, 70, 74, 95, \n            83, 65, 94, 66, 65, \n            65, 75, 84, 55, 73, \n            68, 72, 67, 53, 65)\n\n\n\n1b\nMake a simple descriptive analysis of the variable, what are the mean, median, maximum, minimum and quantiles?\nHow to interpret the data?\n\nmean(weight)\n\n[1] 70.7\n\nmedian(weight)\n\n[1] 69\n\nmax(weight)\n\n[1] 95\n\nmin(weight)\n\n[1] 50\n\n# alternatively, \nsummary(weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   50.0    65.0    69.0    70.7    75.0    95.0 \n\n\n\n\n1c\nMake a histogram.\n\nhist(weight)\n\n\n\n\n\n\n1d\nMake a boxplot. What do the two dots on the top represent?\n\nboxplot(weight)\n\n\n\n\nThey are the largest two points in the dataset. These are outliers in this data.\n\n\n\n\n\n\n(Optional) Outliers in box plot\n\n\n\n\n\nThere are different ways to define outliers. The default box plot in R determines points beyond \\(Q_1 - 1.5\\times IQR\\) and \\(Q_3 + 1.5\\times IQR\\) are outliers. You can check the values of quartiles using summary(), and read up the documentation ?boxplot()."
  },
  {
    "objectID": "lab/lab_eda_part1.html#exercise-2-lung-function",
    "href": "lab/lab_eda_part1.html#exercise-2-lung-function",
    "title": "Exploratory data analysis (Part I)",
    "section": "Exercise 2 (lung function)",
    "text": "Exercise 2 (lung function)\nLung function has been measured on 106 medical students. Peak expiratory flow rate (PEF, measured in liters per minute) was measured three times in a sittinng position, and three times in a standing position.\nThe variables are\n\nAge (years)\nGender (1 is female, 2 is male)\nHeight (cm)\nWeight (kg)\nPEF measured three times in a sitting position (pefsit1, pefsit2, pefsit3)\nPEF measured three times in a standing position (pefsta1, pefsta2, pefsta3)\nMean of the three measurements made in a sitting position (pefsitm)\nMean of the three measurements made in a standing position (pefstam)\nMean of all six PEF values (pefmean)\n\n\n2a)\nDownload and open PEFH98-english.dta into R.\nIf you have problem with .dta data format, you can also use PEFH98-english.csv.\nPay attention to how gender is coded. We might have to modify it.\n\n# locate your datafile, set the path to your data\n# lung_data <- haven::read_dta('data/PEFH98-english.dta')\nlung_data <- read.csv('data/PEFH98-english.csv', sep = ',')\nhead(lung_data)\n\n  age gender height weight pefsit1 pefsit2 pefsit3 pefsta1 pefsta2 pefsta3\n1  20      1    165     50     400     400     410     410     410     400\n2  20      2    185     75     480     460     510     520     500     480\n3  21      2    178     70     490     540     560     470     500     470\n4  21      2    179     74     520     530     540     480     510     500\n5  20      2    196     95     740     750     750     700     710     700\n6  20      2    189     83     600     575     600     600     600     640\n   pefsitm  pefstam  pefmean\n1 403.3333 406.6667 405.0000\n2 483.3333 500.0000 491.6667\n3 530.0000 480.0000 505.0000\n4 530.0000 496.6667 513.3333\n5 746.6667 703.3333 725.0000\n6 591.6667 613.3333 602.5000\n\n# gender is coded as 1 and 2, but it looks like it's not a category but an integer (number)\n# we code it explicitly fo readability\nlung_data$gender <- factor(lung_data$gender, \n                           levels = c('1','2'),\n                           labels = c('female','male')) \nhead(lung_data)\n\n  age gender height weight pefsit1 pefsit2 pefsit3 pefsta1 pefsta2 pefsta3\n1  20 female    165     50     400     400     410     410     410     400\n2  20   male    185     75     480     460     510     520     500     480\n3  21   male    178     70     490     540     560     470     500     470\n4  21   male    179     74     520     530     540     480     510     500\n5  20   male    196     95     740     750     750     700     710     700\n6  20   male    189     83     600     575     600     600     600     640\n   pefsitm  pefstam  pefmean\n1 403.3333 406.6667 405.0000\n2 483.3333 500.0000 491.6667\n3 530.0000 480.0000 505.0000\n4 530.0000 496.6667 513.3333\n5 746.6667 703.3333 725.0000\n6 591.6667 613.3333 602.5000\n\n\n\n\n2b)\nHow many observations are there (number of subjects)? How do you get a list of variable names from your dataset?\n\nnrow(lung_data)\n\n[1] 106\n\ncolnames(lung_data)\n\n [1] \"age\"     \"gender\"  \"height\"  \"weight\"  \"pefsit1\" \"pefsit2\" \"pefsit3\"\n [8] \"pefsta1\" \"pefsta2\" \"pefsta3\" \"pefsitm\" \"pefstam\" \"pefmean\"\n\n\nMake a histogram for each of the following variables. Compute means, and interpret the results.\nheight\nweight\nage\npefsitm\npefstam\n\nhist(lung_data$height)\n\n\n\n\nWe repeat it for the other 4 variables. We can put them more compactly,\n\npar(mfrow = c(2, 2)) \n# we use this line to display (2 rows 2 columns)\n# by default it is 1 row 1 column\n# run this line to set it back to default:\n# par(mfrow = c(1, 1))\nhist(lung_data$weight)\nhist(lung_data$age)\nhist(lung_data$pefsitm)\nhist(lung_data$pefstam)\n\n\n\n\n\n\n2c)\nMake histograms for the variables height and pefmean for men and women separately. Also try to make boxplots.\nWhat conclusion can you draw?\n\nheight_f <- lung_data$height[lung_data$gender == 'female']\nheight_m <- lung_data$height[lung_data$gender == 'male']\n\npar(mfrow = c(1,2)) # plot in parallel\nhist(height_f)\nhist(height_m)\n\n\n\n# we can make it more customized\n# add axis limit, title and xaxis name\npar(mfrow = c(1,2)) # plot in parallel\nhist(height_f, main = 'Height: female', xlab = 'Height (cm)',\n     xlim = c(150, 200))\nhist(height_m, main = 'Height: male', xlab = 'Height (cm)',\n     xlim = c(150, 200))\n\n\n\n\nSimilarly, histogram for pefmean can be done in the same way.\n\npefmean_f <- lung_data$pefmean[lung_data$gender == 'female']\npefmean_m <- lung_data$pefmean[lung_data$gender == 'male']\n\npar(mfrow = c(1,2)) # plot in parallel\nhist(pefmean_f)\nhist(pefmean_m)\n\n\n\n\nNow we can make some boxplots\n\npar(mfrow = c(1, 2))\nboxplot(height ~ gender, data = lung_data, main = 'Height vs Gender')\n\n# it is also possible to remove the frame\nboxplot(pefmean ~ gender, data = lung_data, frame = F, main = 'PEFmean vs gender')\n\n\n\n\n\n\n2d)\nMake three scatterplots to compare\n\npefmean with height\npefmean with weight\npefmean with age\n\nWhat association do you see?\n\n# pefmean height\nplot(lung_data$pefmean, lung_data$height)\n\n\n\n# it is possible to customize \nplot(lung_data$pefmean, lung_data$height, \n     main = 'PEF mean vs height', \n     xlab = 'PEF mean', ylab = 'Height',\n     pch = 20)\n\n\n\n# pch: plotting symbols\n\npch = 20 is setting the symbol to small solid dots. You can try different values, from 0 to 25. Read more\n\npar(mfrow = c(1, 2))\n# pefmean weight\nplot(lung_data$pefmean, lung_data$weight, \n     main = 'PEF mean vs weight', \n     xlab = 'PEF mean', ylab = 'Weight',\n     pch = 20)\n\n# pefmean age\nplot(lung_data$pefmean, lung_data$age, \n     main = 'PEF mean vs age', \n     xlab = 'PEF mean', ylab = 'Age',\n     pch = 20)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the course",
    "section": "",
    "text": "The aim of the course is to make the participants acquainted with basic statistical ideas and methods. No special previous knowledge of mathematics or statistics is assumed. The statistical software R and the RStudio environment will be used in many of the exercises. Analysis of examples from biomedical research will be emphasized.\n\nContact\n\nManuela Zucknick: manuela.zucknick@medisin.uio.no\nValeria Vitelli: valeria.vitelli@medisin.uio.no\nAlvaro Kohn Luque: a.k.luque@medisin.uio.no\nChi Zhang: chi.zhang@medisin.uio.no"
  },
  {
    "objectID": "lab/overview.html",
    "href": "lab/overview.html",
    "title": "R Lab and Code",
    "section": "",
    "text": "Welcome! Here you will find material for R lab and code for this course. Lecture notes, videos and other resources can be found in Course material page."
  },
  {
    "objectID": "lab/overview.html#useful-resources",
    "href": "lab/overview.html#useful-resources",
    "title": "R Lab and Code",
    "section": "Useful resources",
    "text": "Useful resources\nList of commands that are useful for this course: list of commands\nBook (Wickham et al) R for Data Science (2e)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MF9130E - Introductory course in Statistics",
    "section": "",
    "text": "Welcome!\nYou are on the course website for MF9130E - Introductory Course in Statistics.\n\nThe course is intended for students and researchers who are interested in statistics and R programming, with applications in medical and healthcare data. No previous programming experience is required to participate in this course.\nThis website is developed by the instructors of the course, hosted for free and public access on Github. The course github repository can be accessed here.\nYou can check the course page by UiO for information related to applications, evaluations and other administrative matters.\nAbout home exam: information regarding home exam will be talked about in the class on the first and last days. Assignment tasks for home exam will be put in Canvas, and you should submit your assignment in Inspera. More information about the exam\n\n\nPreparation\nYou should have a working solution of R (either installed on your own laptop, or using Posit cloud) before the course.\nIt would also be helpful if you familiarize yourself with the course website.\n\nGet Started provides some information about software installation, where to download data and code, and some resources.\nCourse material provides an overview of the material and corresponding links for each session.\nR Lab and Code hosts the lab session notes.\n\n\n\n\nSchedule\nYou can find the official course schedule provided by University of Oslo here. If there is an error in the time and place on this page, please refer to the official schedule.\n\nWeek 1\n\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\nPlace\n\n\n\n\nApr 24\n12:45-16:00\nLecture: course introduction, data and descriptive statistics\nDME, Lille auditorium\n\n\nApr 25\n08:30-11:45\nGuided lab session: introduction to R, descriptive statistics with R\nDME, Auditorium 13\n\n\nApr 25\n12:45-16:00\nLecture: probability, Bayes law, diagnostic tests, distributions\nDME, Auditorium 13\n\n\nApr 26\n08:30-11:45\nGuided lab session\nDME, Store auditorium\n\n\nApr 26\n12:45-16:00\nLecture: statistical inference, hypothesis testing, confidence intervals, t-tests\nDME, Store auditorium\n\n\nApr 27\n08:30-11:45\nGuided lab session\nDME, Runde auditorium R105\n\n\nApr 27\n12:45-16:00\nLecture: categorical data analysis\nDME, Runde auditorium R105\n\n\nApr 28\n08:30-11:45\nGuided lab session\nDME, Store Auditorium\n\n\n\n\n\nWeek 2\n\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\nPlace\n\n\n\n\nMay 8\n08:30-11:45\nLecture and lab: exploratory data analysis, transformation, non-parametric methods\nDME, Lille auditorium\n\n\nMay 8\n12:45-16:00\nLecture and lab: sample size, statistical power\nDME, Lille auditorium\n\n\nMay 9\n08:30-11:45\nLecture: study designs, principle of clinical trials\nHelga Engs hus Auditorium 3\n\n\nMay 9\n12:45-16:00\nLecture and lab: regression I\nHelga Engs hus Auditorium 3\n\n\nMay 10\n08:30-11:45\nLecture: regression II\nDME, Auditorium 13\n\n\nMay 10\n12:45-16:00\nLecture and lab: regression II\nDME, Auditorium 13\n\n\nMay 11\n08:30-11:45\nLecture and lab: regression III\nDME, Auditorium 13\n\n\nMay 11\n12:45-16:00\nLecture and lab: survival analysis, course summary\nDME, Auditorium 13"
  },
  {
    "objectID": "course_material/notes_probability.html",
    "href": "course_material/notes_probability.html",
    "title": "Probability",
    "section": "",
    "text": "Topics:\nBooks and resources:"
  },
  {
    "objectID": "course_material/notes_probability.html#basic-concepts",
    "href": "course_material/notes_probability.html#basic-concepts",
    "title": "Probability",
    "section": "Basic concepts",
    "text": "Basic concepts\nA probability expresses a potential for something to happen.\nIt is an assessment of uncertainty in a situation or event.\nIt corresponds to the concept of risk in medicine.\n\nBrief history\nBlaise Pascal (17th century) was the founder of probability theory, the set of basic rules for doing probability calculations. His work was motivated by dice and card games.\nAndrey Kolmogorov formulated the exact probability rules as late as 1933.\n\n\nTwo definitions of probability\nFrequentist definition: Proportions of times (or frequency) that some event occurs in a large number of similar repeated trials.\nBayesian definition: Degree of belief in the occurrence of an event.\n\n\n\n\n\n\nObservation\n\n\n\n\n\nIn this course we focus in the frequentist definition, the most widely used. However, we will see at the end of this section that the Bayesian definition is important as it constitutes the foundation of the Bayesian approach to statistics, after Thomas Bayes (18th century).\n\n\n\n\n\nLaw of Large Numbers\n“As an experiment is repeated over and over, the observed frequency approaches the true probability”.\n\n\n\n\n\n\nExample: Coin tossing\n\n\n\n\n\nThis figure shows the frequency of heads in up to 200 simulated coin tosses. We can see that the frequency approaches the value 0.5 as the number of tosses grows.\n\n\n\n\nThe frequentist view of probability interprets the frequency of an event in a large number of experiments as its probability.\n\n\n\n\n\n\nExample: Births in Norway\n\n\n\n\n\nGiving birth to a girl or a boy is perceived as a random event. This table contains the frequencies of occurrence of the event “giving birth to a girl” in Norway during 2019-2022\n\nSource: Statistisk sentralbyrå\n\n\n\n\n\n\n\n\n\nYear\nTotal number of births\nNumber of boys\nNumber of girls\nPercentage of girls\n\n\n\n\n2022\n51480\n26445\n25035\n48.6\n\n\n2021\n56060\n28684\n27376\n48.8\n\n\n2020\n52979\n27063\n25916\n48.9\n\n\n2019\n54495\n28042\n26453\n48.5\n\n\n\nThe probability of giving birth to a girl in Norway is approximately 0.49"
  },
  {
    "objectID": "course_material/notes_probability.html#probability-calculations",
    "href": "course_material/notes_probability.html#probability-calculations",
    "title": "Probability",
    "section": "Probability calculations",
    "text": "Probability calculations\n\nStochastic trial, events and sample space.\nA stochastic trial is characterized by an uncertain outcome.\nAll possible outcomes in a stochastic trial make up the sample space.\nAn event can be a single outcome, or a collection of single outcomes.\nEach event has a probability of ocurrence between 0 and 1. A probability equal to 0 means that the event can never occur, and equal to 1 means that the event is certeinly occuring.\nThe sum of all probabilities in a sample space equals 1.\n\n\n\n\n\n\nExamples: Stochastic trials\n\n\n\n\n\nDice tossing\n\nSample space: {1,2,3,4,5,6}\nEvents:\n\nEven number of eyes: {2,4.6}\nMore than 3 eyes: {4,5,6}\n\n\nChild birth\n\nSample space: {B,G}\nEvents:\n\nHaving a girl: {G}\nNot having a girl: {B}\n\n\nDiastolic blood pressure\n\nSample space: {40,41,…,119,120}\nEvent:\n\nHypertension: {91,92, …, 120}\n\n\n\n\n\n\n\nVenn diagram\nVenn diagrams are often used to illustrate events. In the figures below A and B represent different events and S is the sample space.\n\n\n\n\n\n\n\n\n\n\n\n\nOperators on events:\n\nUnion: \\(A \\cup B\\)\nIntersection: \\(A \\cap B\\)\nComplement: \\(\\bar{A}\\)\n\n\n\n\n\n\n\n\n Union: \\(A \\cup B\\)\n Intersection: \\(A \\cap B\\)\n\n\n\n\n\n\n\n\n\n\n Complement: \\(\\bar{A}\\)\n Combining operators: \\(A \\cap \\bar{B}\\)\n\n\n\n\n\nProbability calculation rules\nThe probability of an event \\(A\\) is denoted by \\(P(A)\\). It has a value between 0 and 1. The probability over the whole sample space equals 1.\nComplement rule\n\\[P(A) + P(\\bar{A}) = 1\\]\nAdditive rule\nThe occurrence of at least one of the events \\(A\\) or \\(B\\) is \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\] For disjoint events \\(A\\) and \\(B\\), \\(P(A \\cap B) = 0\\). Hence \\[P(A \\cup B) = P(A) + P(B)\\]\nMultiplicative rule\nProbability of independent events \\(A\\) and \\(B\\) can be multiplied\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\n\n\n\n\nExample: Child gender in two births\n\n\n\n\n\nWhat is the probability of giving birth to at least one girl?\n\nWe assume the probability of giving birth to a girl is 0.5.\nWe assume that the two births are independent events.\n\n\\[\n\\begin{aligned}\nP(\\text{at least one girl}) & =P(\\text{1st child is girl}) + P(\\text{2nd child is girl})-P(\\text{both are girls}) \\\\\n& = 1/2 + 1/2 - 1/2 \\times 1/2 = 3/4\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nExample: Tossing two dices\n\n\n\n\n\n\nThe two tosses are independent events.\nThere are 36 equally possible outcomes.\nOnly one outcome corresponds to the double 6 event.\n\nWhat is the probability of getting 6 in the first AND the second throw? \\[\nP(\\text{6 in the first AND the second throw}) = 1/6 \\times 1/6 = 1/36\n\\]\nWhat is the probability of getting at least one 6 in two throws? \\[\n\\begin{aligned}\n    P(\\text{at least one 6 in 2 trows}) &=P(\\text{6 in the first}) +         P(\\text{6 in the second}) - P(\\text{6 in both})\\\\\n    &=1/6 +1/6 - 1/36 =0.31\n\\end{aligned}\n\\]\nWhat is the probability of not getting any 6 in two throws? \\[\n\\begin{aligned}\n    P(\\text{not getting any 6 in 2 trows}) &= 1 - P(\\text{at least one 6 in 2 trows})\\\\\n    &= 1 - 0.31 = 0.69\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "course_material/notes_probability.html#conditional-probability",
    "href": "course_material/notes_probability.html#conditional-probability",
    "title": "Probability",
    "section": "Conditional probability",
    "text": "Conditional probability\nWhat is the probability of getting the outcome \\(A\\) given that the event \\(B\\) has occur? For example, what is the risk of becoming sick from COVID-19 given that your spouse already is?\nThe idea to define such a conditional probability of \\(A\\) given \\(B\\), denoted \\(P(A|B)\\), is to consider \\(B\\) as the new sample space and rescale the probability of events in \\(B\\), such that the new sample space has probability 1:\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\n\n\n\n\n\nExercise: Weather forecast\n\n\n\n\n\nThis table contains the frequency of joint events: weather forecast and actual weather.\n\n\n\n\nsunny forecast\ncloudy forecast\nrainy forecast\n\n\nsunny weather\n0.3\n0.05\n0.05\n\n\ncloudy weather\n0.04\n0.2\n0.02\n\n\nrainy weather\n0.1\n0.04\n0.2\n\n\n\n\nWhich is the probability of a sunny day?\nWhich is the probability that the forecast is wrong?\nWhich is the probability of rain when the forecast is sunny?\n\nHint: remember to use the special case of the additive rule, holding when A and B are disjoint, \\(P(A \\cup B) = P(A) + P(B)\\)\n\n\n\n\nStochastic independence\nThe events \\(A\\) and \\(B\\) are independent if \\(P(A|B) = P(A)\\)\nInterpretation: probability of \\(A\\) is the same if we also know that \\(B\\) has occurred.\n\n\n\n\n\n\nExamples: independence\n\n\n\n\n\nConsider the following:\n\n\\(A\\): Probability of me having the condition\n\\(B\\): Probability of my partner having the same condition\n\nCondition 1: Diabetes, \\(P(A|B) = P(A)\\)\nCondition 2: COVID-19, \\(P(A|B) \\neq P(A)\\)\n\n\n\nProbability calculations can be simplified if there is stochastic independence:\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)} = P(A)\\]\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\n\n\n\n\nExample: Child birth (revisited)\n\n\n\n\n\nTwo children are born, which is the probability that genders are different?\n\\[\\begin{aligned}\nP(\\text{girl and boy}) & =P(\\text{girl then boy}) + P(\\text{boy then girl})\\\\\n& = P(\\text{first is girl}) \\times P(\\text{second is boy}) +\\\\\n&~~~~+ P(\\text{first is boy}) \\times P(\\text{second is girl})\\\\\n& = 1/2 \\times 1/2 + 1^/2 \\times 1/2 = 0.50\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\n\nExample: Dices (revisited)\n\n\n\n\n\nThree dices are tossed, which is the probability of all showing sixes?\n\\[P(\\text{three 6})=1/6 + 1/6 + 1/6 = 1/216 = 0.004\\]\n\n\n\n\n\n\n\n\n\nExercise: Side effects of medication\n\n\n\n\n\nA treatment has a side effect which has a risk of 1/1000. Which is the probability that the side effect does not occur among 1000 patients?\nHint: think about independence."
  },
  {
    "objectID": "course_material/notes_probability.html#total-probability",
    "href": "course_material/notes_probability.html#total-probability",
    "title": "Probability",
    "section": "Total probability",
    "text": "Total probability\nThe law of total probability expresses the probability of an outcome, \\(P(A)\\), which can be realized via two distinct events \\(B\\) and \\(\\bar{B}\\):\n\\[P(A) = P(A|B)P(B) + P(A| \\bar{B})P( \\bar{B})\\]\n\n\n\n\n\n\nDerivation of the law of total probability\n\n\n\n\n\nAny event \\(A\\) can be divided in two with regard to another event \\(B\\):\n\\[A = (A \\cap B) \\cup (A \\cap \\bar{B})\\]\n\nBecase the two events \\((A \\cap B)\\) and \\((A \\cap \\bar{B})\\) are disjunct, we can write:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap \\bar{B})\n\\] Using the multiplicative rule, we get the law of total probability:\n\\[\nP(A) = P(A|B)P(B) + P(A| \\bar{B})P( \\bar{B})\n\\]\n\n\n\n\n\n\n\n\n\nExample: Gender of twins\n\n\n\n\n\n\nWe want to find the probability of two twins having the same gender.\nMonozygotic twins have the same gender, while dizygotic twins are like any other siblings.\nWe have to take into consideration if the twins are monozygotic or not. For that we use the law of total probability.\n\n\\(A\\) = Both twins have the same gender.\n\\(B\\) = The twins are monozygotic.\n\nWe want to find \\(P(A)\\)\nWe assume that the probability of twins being monozygotic, \\(P(B)\\), is 1/3.\nThe law of total probability give us:\n\n\\[\n\\begin{aligned}\nP(A) & = P(A|B)P(B) + P(A| \\bar{B})P( \\bar{B})\\\\\n& = 1 \\cdot 1/3 + 1/2 \\cdot 2/3 = 0.67\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "course_material/notes_probability.html#bayes-theorem-also-called-bayes-law",
    "href": "course_material/notes_probability.html#bayes-theorem-also-called-bayes-law",
    "title": "Probability",
    "section": "Bayes’ theorem (also called Bayes’ law)",
    "text": "Bayes’ theorem (also called Bayes’ law)\nGiven two events \\(A\\) and \\(B\\), Bayes theorem states that:\n\\[\nP(B|A)=\\frac{P(A|B)P(B)}{P(A)}\n\\]\n\n\n\n\n\n\nExplain\n\n\n\n\n\nIt was first formulated by Thomas Bayes (1702-1761)\nBayes law relates the conditional probabilities \\(P(B|A)\\) and \\(P(A|B)\\)\n\n\n\n\n\n\n\n\n\nExample Gender of twins (revisited)\n\n\n\n\n\nWhat if we want to find the probability that two twins of the same gender are monozygotic?\nIn other words, what is \\(P(B|A)\\)?\nWe can use Bayes’ law and the law of total probability\n\\[\n\\begin{aligned}P(B|A) & =\\frac{P(A|B)P(B)}{P(A)}\\\\       & =\\frac{P(A|B)P(B)}{P(A|B)P(B) + P(A| \\bar{B})P( \\bar{B})}\\\\       & = \\frac{1 \\cdot 1/3}{1 \\cdot 1/3 + 1/2 \\cdot 2/3} = 0.5\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "course_material/notes_probability.html#bayesian-statistics",
    "href": "course_material/notes_probability.html#bayesian-statistics",
    "title": "Probability",
    "section": "Bayesian statistics",
    "text": "Bayesian statistics\nIn the Bayesian definition of probability, the size of the probability of a given event represents ones degree of belief in the occurrence of the even.\nWhere does Bayes come in? Bayes’ law is used to calculate such probabilities base on on our prior belief and available data:\n\\[\nP(\\theta|data) =\\frac{P(data|\\theta)P(\\theta)}{P(data)}\n\\]\n\n\\(\\theta\\) refers to the parameters in your model (mean, variance, etc.)\nThe prior distribution \\(P(\\theta)\\) is where you put in your prior beliefs\nWhat you want to estimte is the so called posterior distribution \\(P(\\theta|data)\\), the probability distribution of the model parameters given your data.\nThe more data you have, the more will it dominate over your prior belief.\nWhen youy have prior knowledge about your problem, you get to actually use this information\nWhen you know little (or nothing) of your problme, there are anyway many methodological advantages in using Bayesian statistics\nBayesian statistics is not really relevant for simpler problems like in this course, but you will probaly at some point come across articles using Bayesian approaches."
  },
  {
    "objectID": "course_material/notes_diagnostic_tests.html",
    "href": "course_material/notes_diagnostic_tests.html",
    "title": "Evaluation of Diagnostic Tests",
    "section": "",
    "text": "Topics:\nBook and resources:"
  },
  {
    "objectID": "course_material/notes_diagnostic_tests.html#confusion-matrix",
    "href": "course_material/notes_diagnostic_tests.html#confusion-matrix",
    "title": "Evaluation of Diagnostic Tests",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nDenote the subjects with the condition as \\(P\\), and subjects without the condition as \\(N\\).\nTotal population: \\(P+N\\)\nPrevalence (of the condition) is defined as: \\(\\frac{P}{P+N}\\)\n\n\n\n\n\n\n\n\n\n\nPredicted Positive\nPredicted Negative\nTotal\n\n\n\n\nWith condition\nTrue Positive TP\nFalse Negative FN\n\\(P = TP + FN\\)\n\n\nWithout condition\nFalse Positive FP\nTrue Negative TN\n\\(N=FP + TN\\)\n\n\nTotal\n\\(P_{\\text{predicted}}=TP+FP\\)\n\\(N_{\\text{predicted}}=FN + TN\\)\n\n\n\n\nSensitivity of a diagnostic test is the probability of revealing that a person has the condition. It is also known as true positive rate (TPR), as it is the proportion of true positives.\n\\[\\text{Sensitivity}= \\frac{TP}{P} = \\frac{TP}{TP+FN}\\]\nSpecificity is the probability of revealing that a person does not have the condition (i.e. healthy). It is also known as true negative rate (TNR), as it is the proportion of true negatives.\n\\[\\text{Specificity} = \\frac{TN}{N} = \\frac{TN}{TN + FP}\\]\nPositive predictive value (PPV): probability that the person with the condition was given a positive test result\n\\[PPV = \\frac{TP}{P_{predicted}} = \\frac{TP}{TP + FP}\\]\nNegative predictive value (NPV): probability that the person without the condition (i.e. healthy) was give a negative test result.\n\\[NPV = \\frac{TN}{N_{predicted}} = \\frac{TN}{TN + FN}\\]\n\n\n\n\n\n\nExample: Mammography\n\n\n\n\n\n(From the Norwegian Medical Journal, 1990) 372 women with a lump in the breast initially classified as malign or benign were referred to a surgical clinic for a final diagnosis.\n\n\n\n\nMammography malign\nMammography benign\n\n\n\n\nFinal diagnosis malign\n22\n3\n\n\nFinal diagnosis benign\n16\n331\n\n\n\nWe identify the positive test result (mammography malign), and the positive condition (final diagnosis malign). Then we can compute the four following probabilities from the table:\nSensitivity: \\(22/(22+3) = 0.88\\)\nSpecificity: \\(331/(331+16) = 0.95\\)\nPositive predictive value: \\(22/(22+16) = 0.58\\)\nNegative predictive value: \\(331/(331+3) = 0.99\\)"
  },
  {
    "objectID": "course_material/notes_diagnostic_tests.html#diagnostic-tests-and-prevalence",
    "href": "course_material/notes_diagnostic_tests.html#diagnostic-tests-and-prevalence",
    "title": "Evaluation of Diagnostic Tests",
    "section": "Diagnostic tests and prevalence",
    "text": "Diagnostic tests and prevalence\nThe concepts in diagnostic testing can be formulated in the form of conditional probabilities:\n\nSensitivity: \\(P(\\text{pos}|\\text{ill})\\)\nSpecificity: \\(P(\\text{neg}|\\text{healthy})\\)\nPositive predictive value: \\(P(\\text{ill}|\\text{pos})\\)\nNegative predictive value: \\(P(\\text{healthy}|\\text{neg})\\)\n\nBayes’ theorem can be applied to compute PPV and NPV from sensitivity, specificity and prevalence:\n\\[PPV = \\frac{\\text{sens} \\cdot \\text{prev}}{\\text{sens} \\cdot \\text{prev} + (1-\\text{spec}) \\cdot (1-\\text{prev})}\\]\n\\[NPV = \\frac{\\text{spec} \\cdot (1-\\text{prev}) }{(1-\\text{sens}) \\cdot \\text{prev} + \\text{spec} \\cdot (1-\\text{prev})}\\]\n\n\n\n\n\n\nDerivation of the PPV formula using Bayes’ law\n\n\n\n\n\n\\[\n\\begin{aligned}PPV = P(\\text{ill}|\\text{pos}) & = \\frac{P(\\text{pos}|\\text{ill}) \\cdot P(\\text{ill})}{P(\\text{pos})}\\\\                               & = \\frac{P(\\text{pos}|\\text{ill}) \\cdot P(\\text{ill})}{P(\\text{pos}|\\text{ill}) \\cdot P(\\text{ill}) +  P(\\text{pos}|\\text{healthy}) \\cdot P(\\text{healthy})}\\\\ & =\\frac{\\text{sens} \\cdot \\text{prev}}{\\text{sens} \\cdot \\text{prev} + (1-\\text{spec}) \\cdot (1-\\text{prev})}\\end{aligned}\n\\]\nExercise: Try to derive the formula for \\(NPV\\) in a similar way.\n\n\n\n\n\n\n\n\n\nExample: HIV testing\n\n\n\n\n\nIn a test for the HIV virus, the result can be:\n\nPositive: the test shows antibodies.\nNegative: the test does not show antibodies.\n\nBut the test result may be wrong:\n\nA false positive might come from antibodies from related virus, but not HIV.\nA false negative might be due to the fact that antibodies are not yet produced in sufficient quantity, hence are not detected by the test.\n\nWe assume that the sensitivity of the HIV test is 98%. We know that the specificity of the HIV test is 99.8%. We assume that the prevalence of HIV in a given population is 0.1%.\nWhat is the probability of a person having HIV, if he got a positive test result?\n\\(PPV = \\frac{\\text{sens} \\cdot \\text{prev}}{\\text{sens} \\cdot \\text{prev} + (1-\\text{spec}) \\cdot (1-\\text{prev})} = \\frac{0.98 \\times 0.001}{0.98 \\times 0.001 + 0.002 \\times 0.999} = 0.329\\)\nWhat is the probability of a person not having HIV, if he got a negative test result?\n\\(NPV = \\frac{\\text{spec} \\cdot (1-\\text{prev}) }{(1-\\text{sens}) \\cdot \\text{prev} + \\text{spec} \\cdot (1-\\text{prev})} = \\frac{0.998 \\times 0.999}{0.98 \\times 0.001 + 0.998 \\times 0.999} = 0.999\\)\nLet us see from 100 000 persons, what are the theoretical results of the test?\n\nNumber of HIV infected (positive condition): \\(100000 \\times 0.001 = 100\\)\nTrue positives: \\(100 \\times 0.98 = 98\\)\nFalse negatives: 2\nNumber of not HIV infected (negative condition): \\(100000-100 = 99900\\)\nTrue negatives: \\(99900 \\times 0.998 = 99700\\)\nFalse positives: \\(200\\)\n\nNote that from 298 positive tests, only 98 persons have HIV. How would these numbers change if the prevalence would be lower? and if it would be higher?"
  }
]